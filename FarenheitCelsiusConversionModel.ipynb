{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # pip install tensorflow, you will orb get an error so just go to the web it gives you and copy the command to enable big routes\n",
    "import numpy as np # pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "celsius = np.array([-40, -10, 0 , 8, 15, 22, 38, 100, 1, 5, 33], dtype=float)\n",
    "farenheit = np.array([-40, 14, 32, 46, 59, 72, 100, 212, 33.8, 41, 91.4], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(units=1, input_shape=[1]) # Dense keras stablishes connections between each info entering array to each result array\n",
    "# in this case we just got 2 neuron (celsius[entering_info_neuron], farenheit[exit_info_neuron]), in this case, units is the exit neuron layer\n",
    "# and input_shape is the entering neuron layer, each layer may have more than 1 neuron but in this case is just a 1 on 1 layer relation\n",
    "model = tf.keras.Sequential([layer]) # to work with layers we need a keras model to treat with layers, in this case a sequential based model\n",
    "\n",
    "# I got this warning executing so just read documentation to understand the reasoning behind it\n",
    "# C:\\Users\\eric\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "#  super().__init__(activity_regularizer=activity_regularizer, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.1), # This optimizer allows the net how to adjust the weights and biases in an efficient way so it\n",
    "    # learns instead of un-learning, the numeric value (0.05) is the learning rate, the lower the number is, the lower our net will learn, but,\n",
    "    # the more accurate the learning and responses will be, if the number is too high, our net will learn faster but can potentially be\n",
    "    # inacurate so, just go find out how much do you need the net to work on the result\n",
    "    \n",
    "    loss='mean_squared_error' # the lost function determines the balaance between, number of errors and how different erros will be, in this case,\n",
    "    # it considers that a little amount of bigg errors is worse than a large amount of little errors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE IS WHERE MAGIC IS PRODUCED\n",
    "print(\"Starting training...\")\n",
    "history = model.fit(celsius, farenheit, epochs=2000, verbose=False) # we call our model functionality, fit(), to train our model with the two\n",
    "# neurons we have defined previously, we declare how many tries should be done, in this case 5000, just because i wanted it to train really hard\n",
    "# and set verbose to false because it says too much bullshit when the model is training\n",
    "print(\"Training finished!\") # The execution lasted 45.3 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # Here we are going to see the result of the loss function\n",
    "# this funcitons tell us how wrong where the net results for each try it made\n",
    "plt.xlabel(\"Tries\")\n",
    "plt.ylabel(\"Loss magnitude\")\n",
    "plt.plot(history.history[\"loss\"]) # generate the graphic with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL EXAM\n",
    "print(\"Let's do a prediction...\")\n",
    "result = model.predict(np.array([29.0]))\n",
    "print(f\"The result of conversion from 29.0 celsius is... {result} farenheit!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
